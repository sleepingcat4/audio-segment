This playful project demonstrates how you can slice a GraphQL tutorial video (collected from YouTube) into word-level audio and repurpose it to say something entirely different! Using the word-level timestamps generated by recent transcription models (e.g., Whisper), I was able to segment the audio and then reassemble it to create a new sentence. 

### Goals Achieved:
1. **Word-Level Audio Segmentation**: Split the audio into individual words.
2. **Audio Repurposing**: Used the segmented audio to form a completely new sentence.
3. **Audio Segmentation Explanation**: Showcased how audio segmentation works with transcription models.

### Special Thanks:
A big shout-out to [GLangford](https://github.com/glangford) for the amazing audio segmentation plan that made this possible! Exploring audio models has been a great learning experience, and this project was a fun way to dive deeper into it.

---

Feel free to explore and modify the code for your own audio segmentation experiments!